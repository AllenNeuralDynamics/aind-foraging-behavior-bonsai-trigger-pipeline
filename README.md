# Foraging Behavior Pipeline for Bonsai
(Han Hou @ Aug 2023)

***This is still a temporary workaround until AIND behavior pipeline is implemented.***

## Pipeline structure

![image](https://github.com/AllenNeuralDynamics/aind-foraging-behavior-bonsai-trigger-pipeline/assets/24734299/99723ed4-8e11-4577-8278-36f7ff071ae1)

#### 1. (On Han's PC) Upload raw behavior data to cloud ([github](https://github.com/hanhou/code_cache/blob/master/sync_bonsai/behavior_pipeline_bonsai.py))
   - From all behavior rigs, fetch raw behavior files (.json) generated by the [foraging-bonsai GUI](https://github.com/AllenNeuralDynamics/dynamic-foraging-task)
   - Turn .json files into .nwb files, which contain both data and metadata
   - Upload all .nwb files to a single S3 bucket `s3://aind-behavior-data/foraging_nwb_bonsai/`
     
#### 2. (In Code Ocean, this repo) Trigger computation ([`CO capsule: foraging_behavior_bonsai_pipeline_trigger`](https://codeocean.allenneuraldynamics.org/capsule/9148690/), [github](https://github.com/AllenNeuralDynamics/aind-foraging-behavior-bonsai-trigger-pipeline/blob/main/code/run_capsule.py))
   - Identify unprocessed .nwb files ([github](https://github.com/AllenNeuralDynamics/aind-foraging-behavior-bonsai-trigger-pipeline/blob/c456dcf9bb5f37fc6c836b3a6a53f3c311aa4369/code/run_capsule.py#L31-L48))
   - Send unprocessed .nwb files to [`CO pipeline: Han_pipeline_foraging_behavior_bonsai`](https://codeocean.allenneuraldynamics.org/capsule/8633725/tree).<br>
   In the CO pipeline:
     - Distribute .nwb files to parallel workers ([`CO capsule: foraging_behavior_bonsai_pipeline_assign_job`](https://codeocean.allenneuraldynamics.org/capsule/0827783/tree), [github](https://github.com/AllenNeuralDynamics/aind-foraging-behavior-bonsai-assign-job))
     - Do real analysis on each .nwb file ([`CO capsule: foraging_behavior_bonsai_nwb`](https://codeocean.allenneuraldynamics.org/capsule/5625005/tree), [github](https://github.com/AllenNeuralDynamics/aind-foraging-behavior-bonsai-basic)), where arbitrary dataframes and figures are generated.
   - Collect and combine results from the workers ([`CO capsule: foraging_behavior_bonsai_pipeline_collect_and_upload_results`](https://codeocean.allenneuraldynamics.org/capsule/0579904/tree), [github](https://github.com/AllenNeuralDynamics/aind-foraging-behavior-bonsai-collect-results))
   - Upload results to this S3 bucket `s3://aind-behavior-data/foraging_nwb_bonsai_processed/`

#### 3. (In Code Ocean) Visualization by Streamlit app ([`CO capsule: foraging-behavior-browser`](https://codeocean.allenneuraldynamics.org/capsule/3373065/), [github](https://github.com/AllenNeuralDynamics/foraging-behavior-browser))
The Streamlit app fetches data from the above S3 bucket and generates data viz. You could run the app either on [Code Ocean](https://codeocean.allenneuraldynamics.org/cw/4eb53fe0-a03c-42bb-8c94-add41e78ba8d/proxy/8501/) (recommended) or on [Streamlit public cloud](https://foraging-behavior-browser.streamlit.app/Bonsai)

## Automatic training
See [this repo](https://github.com/AllenNeuralDynamics/aind-foraging-behavior-bonsai-automatic-training)

## How to add more rigs
- On the rig PC, share the data folder on the network.
- Let me know the IP address, path to the data folder, and Windows credentials. I will create a new entry [here](https://github.com/hanhou/code_cache/blob/51485cf3609fa49902a78e404c1f1b60837467e6/sync_bonsai/behavior_pipeline_bonsai.py#L19-L21).

## How to add more analyses
The pipeline is still a prototype at this moment. As you can see in the [Streamlit app](https://foraging-behavior-browser.streamlit.app/Bonsai), so far I only implemented [two basic analyses](https://github.com/AllenNeuralDynamics/aind-foraging-behavior-bonsai-basic/blob/e740865cf7c5ed9c649147156d8b2afada714249/code/process_nwbs.py#L181-L195): 
- compute essential session-wise stats
- generate a simple plot of choice-reward history
  
To add more analyses to the pipeline, just plug in your own function [here](https://github.com/AllenNeuralDynamics/aind-foraging-behavior-bonsai-basic/blob/e740865cf7c5ed9c649147156d8b2afada714249/code/process_nwbs.py#L181-L195). Your function should take `nwb` as an input and generate plots or any other results with filename starting with `session_id`.

If you would like to access the .nwb files directly or do analysis outside Code Ocean (not recommended though), check out this bucket `s3://aind-behavior-data/foraging_nwb_bonsai/`

## Pipeline-ready checklist
Checklist before the pipeline is ready to run:
1. `Han_pipeline_foraging_behavior_bonsai`:
    - No yellow warning sign (otherwise, do a `Reproducible Run` of that capsule first)
    - Check the argument of `foraging_behavior_bonsai_pipeline_assign_job` that controls the number of capsule instances
    - Check the argument of `foraging_behavior_bonsai_nwb` that controls the number of multiprocessing cores of each instance.
       - This number should match the core number of "Adjust Resources for capsule in pipeline"
2. Make sure these capsules are not running (`Status` is four gray dots; VSCode are held or terminated)
   - `foraging_behavior_bonsai_pipeline_assign_job`
   - `foraging_behavior_bonsai_nwb`
   - `foraging_behavior_bonsai_pipeline_collect_and_upload_results`
3. Make sure ***one and only one instance*** of `foraging_behavior_bonsai_pipeline_trigger` is running.
4. Make sure ***one and only one instance*** of `foraging-behavior-bonsai-automatic-training` is running.

## Notes on manually re-process all nwbs and upload S3 database
1. Stop the triggering capsule
2. (optional) Re-generate all nwbs
   - Backup nwb folder on my PC and S3
   - On S3, move the old `/foraging_nwb_bonsai` to a backup folder and create a new `/foraging_nwb_bonsai`
   - Re-generate nwbs from jsons on my PC
3. Backup and clear `/foraging_nwb_bonsai_processed` bucket
   - On S3, copy the folder to a backup folder
   - Clear the old folder
      - **If you don't clear it, at least you should delete `df_sessions.pkl`, `error_files.json`, and `pipeline.log` (they will be appended, not overwritten)**
      - Troubleshooting: when attaching a S3 folder to a capsule, the folder must not be empty (otherwise a "permission denied" error)
4. Manually trigger the batch computation in capsule `foraging_behavior_bonsai_nwb`:
   - Make sure the CPU number of the environment is 16 or more :)
   - Run `processing_nwb.py` manually in parallel (with `LOCAL_MANUAL_OVERRIDE = True`)
5. Manually trigger the collect_and_upload capsule:
   - Manually register a data asset:
      - Use any name, but `mount` must be `data/foraging_behavior_bonsai_pipeline_results`
      - The data asset cannot be registered in VSCode?? @20240303 I can only create data asset outside VSCode.
   - In the capsule `collect_and_upload_restuls`, manually attach the data asset just created, and press `Reproducible Run`.
      - I have adapted `collect_and_upload_restuls` so that it can also accept data that are not in /1, /2, ... like those from the pipeline run.
6. To restore the pipeline, follow above "Pipeline-ready checklist"

## What's next
We will likely be refactoring the pipeline after we figure out the AIND behavior metadata schema, but the core ideas and data analysis code developed here will remain. Stay tuned.
